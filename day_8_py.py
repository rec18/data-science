# -*- coding: utf-8 -*-
"""day 8 .py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vVig-st3LJVxTCyC6qUR-2fWdUK-K74T
"""

import requests as r
url = '''https://en.wikipedia.org/wiki/List_of_Indians_by_net_worth'''
response = r.get(url)
response

html_data = response.content
print(html_data)

from bs4 import BeautifulSoup
soup = BeautifulSoup(html_data)
print('done')

all_data=[]
for index_no, value in enumerate(soup.find_all('tr')):
  if 0<= index_no <= 24:
    #print(index_no, value.text)
    temp_data= value.text.splitlines()
    while '' in temp_data:
      temp_data.remove('')
    all_data.append(temp_data)
print('done')

column = all_data[0]
final_data = all_data[1:]

import pandas as pd
final_column=['Rank','Name','Net Worth(USD)','Company','Source of Wealth','None','None']
rich_list = pd.DataFrame(final_data, columns=final_column)
final_df=rich_list.drop('None',axis = 1)
final_df.to_excel('rich_list.xlsx')
print('done')#we can also mail this data try at home

pip install pymysql

import pymysql as py#run all this on jupitar notebook
conn = py.connect(host = 'localhost',
                  user = 'root',
                  password = '123456789'
                  autocommit = True)
cur = conn.cursor()
query='create database wikipedia;'
cur.execute('query')
table_columns=['rich'+i.replace(' ','_').replace('(USD)','1')  for i in final_df.columns]
table_columns

query_part = ' varchar(255), '.join(table_columns) + ' varchar(255)'

query= '''create table wiki.rich_list('''+query_part+');'
print(query)

for i in final_df.itertuples():
  values = (tuple(i[1:]))
  query=(f'''insert into wiki.rich_list values{values};''')
  #print('done')
  cur.execute(query)
print('done')

